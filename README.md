# DataMining_Final_Project

1. Download the file
2. Open the file in Jupyter.
3. Keep your kaggle username and key handy as I've used opendatasets module to import the data into the environment.
4. Execute the cells one by one and observe the performance of 7 different classification algorithms.


The References used in this project are 

[1] https://www.dataquest.io/blog/naive-bayes-tutorial/ 

[2] https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/ 

[3]https://stackoverflow.com/questions/51085553/scikit-learn-5-fold-cross-validation-train-test-split 

[4]https://www.pythonpool.com/remove-punctuation-python/ 

[5]https://www.analyticsvidhya.com/blog/2021/04/improve-naive-bayes-text-classifier-using-laplace-smoothing/ 

[6]https://www.codingninjas.com/codestudio/library/naive-bayes-and-laplace-smoothing-3905 

[7]https://www.jcchouinard.com/confusion-matrix-in-scikit-learn/

[8]https://www.geeksforgeeks.org/random-forest-classifier-using-scikit-learn/

[9]https://www.geeksforgeeks.org/python-decision-tree-regression-using-sklearn/?ref=lbp

[10]https://www.datacamp.com/tutorial/adaboost-classifier-python

[11]https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/

[12]https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a

[13]https://medium.com/@cmukesh8688/tf-idf-vectorizer-scikit-learn-dbc0244a911a 
